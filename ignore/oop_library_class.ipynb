{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File Manager "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "from datetime import datetime\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "class FileManager:\n",
    "    def __init__(self, aws_access_key, aws_secret_key, region_name, bucket_name):\n",
    "        self.s3 = boto3.client(\n",
    "            's3',\n",
    "            aws_access_key_id=aws_access_key,\n",
    "            aws_secret_access_key=aws_secret_key,\n",
    "            region_name=region_name\n",
    "        )\n",
    "        self.bucket_name = bucket_name\n",
    "\n",
    "    def read_json(self, s3_key):\n",
    "        response = self.s3.get_object(Bucket=self.bucket_name, Key=s3_key)\n",
    "        content = response['Body'].read().decode('utf-8')\n",
    "        return json.loads(content)\n",
    "\n",
    "    def read_txt_file(self, s3_key):\n",
    "        response = self.s3.get_object(Bucket=self.bucket_name, Key=s3_key)\n",
    "        content = response['Body'].read().decode('utf-8')\n",
    "        return content\n",
    "\n",
    "    def write_json(self, s3_key, data):\n",
    "        json_data = json.dumps(data, default=str, indent=4)\n",
    "        self.s3.put_object(\n",
    "            Bucket=self.bucket_name,\n",
    "            Key=s3_key,\n",
    "            Body=json_data,\n",
    "            ContentType=\"application/json\"\n",
    "        )\n",
    "        print(f\"Metadata written to s3://{self.bucket_name}/{s3_key}\")\n",
    "\n",
    "    def check_if_file_exists(self, s3_key):\n",
    "        try:\n",
    "            self.s3.head_object(Bucket=self.bucket_name, Key=s3_key)\n",
    "            return True\n",
    "        except ClientError as e:\n",
    "            # Check if the error is specifically about the object not existing\n",
    "            if e.response['Error']['Code'] == '404':\n",
    "                return False\n",
    "            else:\n",
    "                # Re-raise for other errors\n",
    "                raise\n",
    "\n",
    "    def upload_file(self, obj, s3_key):\n",
    "        if isinstance(obj, dict):\n",
    "            body = json.dumps(obj, default=str, indent=4).encode('utf-8')\n",
    "            content_type = \"application/json\"\n",
    "        elif isinstance(obj, str):\n",
    "            body = obj.encode('utf-8')\n",
    "            content_type = \"text/plain\"\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file type\")\n",
    "        self.s3.put_object(\n",
    "            Bucket=self.bucket_name,\n",
    "            Key=s3_key,\n",
    "            Body=body,\n",
    "            ContentType=content_type\n",
    "        )\n",
    "        print(f\"File uploaded to s3://{self.bucket_name}/{s3_key}\")\n",
    "\n",
    "    def upload_audio_file(self, audio_path, s3_key):\n",
    "        with open(audio_path, 'rb') as f:\n",
    "            audio_data = f.read()\n",
    "        self.s3.put_object(\n",
    "            Bucket=self.bucket_name,\n",
    "            Key=s3_key,\n",
    "            Body=audio_data,\n",
    "            ContentType=\"audio/mpeg\"\n",
    "        )\n",
    "        os.remove(audio_path)\n",
    "        print(f\"Audio file uploaded to s3://{self.bucket_name}/{s3_key} and local file deleted.\")\n",
    "\n",
    "    def download_file(self, s3_key, local_path):\n",
    "        self.s3.download_file(self.bucket_name, s3_key, local_path)\n",
    "        print(f\"File downloaded from s3://{self.bucket_name}/{s3_key} to {local_path}\")\n",
    "\n",
    "    def update_file(self, s3_key, data):\n",
    "        self.write_json(s3_key, data)\n",
    "\n",
    "    def delete_file(self, s3_key):\n",
    "        self.s3.delete_object(Bucket=self.bucket_name, Key=s3_key)\n",
    "        print(f\"File s3://{self.bucket_name}/{s3_key} deleted.\")\n",
    "\n",
    "BUCKET_NAME = 'qanqa-prod'\n",
    "aws_access_key = os.environ.get('AWS_ACCESS_KEY_ID')\n",
    "aws_secret_key = os.environ.get('AWS_SECRET_ACCESS_KEY')\n",
    "region_name = os.environ.get('REGION_NAME')\n",
    "\n",
    "s3_manager = FileManager(aws_access_key=aws_access_key, aws_secret_key = aws_secret_key, region_name=region_name, bucket_name=BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pydantic Models.\n",
    "from enum import Enum\n",
    "from typing import Dict\n",
    "from pydantic import BaseModel, Field\n",
    "from datetime import datetime\n",
    "\n",
    "#User Library defined Data\n",
    "class CourseMetadata(BaseModel):\n",
    "    description: str = Field(\"default\", description=\"Description of the course, e.g., 'Introduction to Python'\")\n",
    "    state: str = Field(\"default\", description=\"Current state of the course, e.g., 'To evaluate'\")\n",
    "    level: str = Field(\"default\", description=\"The level of the course, e.g., 'Beginning'\")\n",
    "    current_grade: str = Field(\"default\", description=\"Current grade in the course, e.g., 'A'\")\n",
    "    goal: str = Field(\"default\", description=\"Goal for the course, e.g., 'Understand the concepts'\")\n",
    "    progress: str = Field(\"default\", description=\"Progress in the course as a percentage, e.g., '30%'\")\n",
    "    required_effort: str = Field(\"default\", description=\"Effort required, e.g., 'Easy'\")\n",
    "    created_at: datetime = Field(..., description=\"Timestamp when the course was created\")\n",
    "\n",
    "class UserLibraryModel(BaseModel):\n",
    "    courses: Dict[str, CourseMetadata] = Field(..., description=\"A dictionary of courses with course names as keys\")\n",
    "\n",
    "# Define Enum for states\n",
    "class PodcastState(Enum):\n",
    "    NOT_AVAILABLE = \"Not Available\"\n",
    "    AVAILABLE = \"Available\"\n",
    "    LISTENED = \"Listened\"\n",
    "\n",
    "class AssessmentState(Enum):\n",
    "    NOT_AVAILABLE = \"Not Available\"\n",
    "    AVAILABLE = \"Available\"\n",
    "    TAKEN = \"Taken\"\n",
    "\n",
    "class EvaluationState(Enum):\n",
    "    EVALUATED = \"Evaluated\"\n",
    "    NOT_AVAILABLE = \"Not Evaluated\"\n",
    "\n",
    "    APPROVED = \"Approved\"\n",
    "    NOT_APPROVED = \"Not Approved\"\n",
    "\n",
    "#Course defined Data\n",
    "class LessonMetadata(BaseModel):\n",
    "    podcast_state: str = Field(..., description=\"State of the podcast, e.g., 'Listened'\")\n",
    "    assessment_state: str = Field(..., description=\"State of the assessment, e.g., 'Taken'\")\n",
    "    evaluation_state: str = Field(..., description=\"State of the evaluation, e.g., 'Evaluated'\")\n",
    "    grade: str = Field(..., description=\"Grade for the lesson, e.g., 'A'\")\n",
    "    created_at: datetime = Field(..., description=\"Timestamp when the lesson was created\")\n",
    "    last_generated_assessment: datetime = Field(..., description=\"Timestamp for the last generated assessment\")\n",
    "    n_iteration: int = Field(..., description=\"Number of iterations\")\n",
    "    document_key_path: str = Field(..., description=\"S3 path for the document key\")\n",
    "    podcast_key_path: str = Field(..., description=\"S3 path for the podcast key\")\n",
    "    assessment_key_path: str = Field(..., description=\"S3 path for the assessment key\")\n",
    "    evaluation_key_path: str = Field(..., description=\"S3 path for the evaluation key\")\n",
    "\n",
    "class CourseModel(BaseModel):\n",
    "    lessons: Dict[str, LessonMetadata] = Field(..., description=\"A dictionary of lessons with lesson names as keys\")\n",
    "\n",
    "#Lesson defined Data:\n",
    "class LessonModel(BaseModel):\n",
    "    lesson_path: str = Field(..., description=\"S3 path for the lesson\")\n",
    "    knowledge_graph_path: str = Field(..., description=\"S3 path for the knowledge graph\")\n",
    "    latest_version: int = Field(..., description=\"The latest version number of the lesson\")\n",
    "    assessments_params: str = Field(..., description=\"Assessment parameters, e.g., 'to be implemented'\")\n",
    "    created_at: datetime = Field(..., description=\"Timestamp when the lesson was created\")\n",
    "    updated_at: datetime = Field(..., description=\"Timestamp when the lesson was last updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial User Workflow:\n",
    "\n",
    "1. Create Course (Add a Folder and create first metadata.json)\n",
    "2. Add a Lesson\n",
    "3. Generate Graph [Edit tracing is included]\n",
    "4. Generate Podcast\n",
    "5. Generate Assessment\n",
    "6. Evaluate Assessment\n",
    "\n",
    "------ Begin with the [Next Iteration] ------\n",
    "\n",
    "While Student keeps evaluating:\n",
    "\n",
    "7. Generate New Assessment\n",
    "8. Evaluate New Assessment\n",
    "\n",
    "------ Grading sufficient: Augment the difficult level. ------\n",
    "\n",
    "9. Reach new Blooms Taxonomy level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File uploaded to s3://qanqa-prod/pablo/metadata.json\n"
     ]
    }
   ],
   "source": [
    "username='robert'\n",
    "from typing import List, Dict\n",
    "from collections import defaultdict\n",
    "\n",
    "class MetadataManager:\n",
    "    def __init__(self, file_manager, base_key, level):\n",
    "        self.file_manager = file_manager\n",
    "        self.base_key = base_key.rstrip(\"/\")  #bucket_name/user_name or bucket_name/user_name/course\n",
    "        self.metadata_key = f\"{self.base_key}/metadata.json\"\n",
    "        self.bucket_name = self.base_key.split('/')[0]\n",
    "        self.username = self.base_key.split('/')[1]\n",
    "        self.level = level\n",
    "        self.path = self.username + '/' + self.base_key.split('/')[2] if self.level == 'course' else self.username\n",
    "\n",
    "    def _parse_metadata(self):\n",
    "        self.payload = self.file_manager.s3.list_objects_v2(Bucket=self.bucket_name, Prefix=self.path)['Contents']\n",
    "        if self.level == 'user':\n",
    "            course_dates = defaultdict(list)\n",
    "            for obj in self.payload:\n",
    "                key_parts = obj['Key'].split('/')\n",
    "                if len(key_parts) >= 3:\n",
    "                    course_name = key_parts[1]\n",
    "                    course_dates[course_name].append(obj['LastModified'])\n",
    "            courses = {}\n",
    "\n",
    "            for course, dates in course_dates.items():\n",
    "                created_at = min(dates) if dates else datetime.utcnow()\n",
    "                courses[course] = CourseMetadata(created_at=created_at)\n",
    "\n",
    "            return UserLibraryModel(courses=courses).dict()\n",
    "\n",
    "        elif self.level == 'course':\n",
    "            lessons_dict = defaultdict(dict)\n",
    "            for obj in self.payload:\n",
    "                key = obj['Key']\n",
    "                key_parts = key.split('/')\n",
    "                # Ensure the key has at least three parts: example_user/username/lesson_name/...\n",
    "                if len(key_parts) >= 3:\n",
    "                    lesson_name = key_parts[2]\n",
    "                    # Determine the file type based on the key\n",
    "                    if len(key_parts) == 4:\n",
    "                        file_name = key_parts[3]\n",
    "                        if file_name == 'document.txt':\n",
    "                            lessons_dict[lesson_name]['document_key_path'] = f\"s3://{self.bucket_name}/{key}\"\n",
    "                        elif file_name == 'podcast.mp3':\n",
    "                            lessons_dict[lesson_name]['podcast_key_path'] = f\"s3://{self.bucket_name}/{key}\"\n",
    "                        elif file_name == 'knowledge_graph.json':\n",
    "                            lessons_dict[lesson_name]['knowledge_graph_key_path'] = f\"s3://{self.bucket_name}/{key}\"\n",
    "                    elif len(key_parts) >= 5:\n",
    "                        # Handle nested paths, e.g., Chapter5/v0/assessments.json\n",
    "                        subfolder = key_parts[3]\n",
    "                        file_name = key_parts[4]\n",
    "                        if subfolder.startswith('v'):\n",
    "                            # Assuming 'v0', 'v1', etc., represent iterations\n",
    "                            iteration_number = int(subfolder[1:])  # Extract the number from 'v0'\n",
    "                            lessons_dict[lesson_name]['n_iteration'] = max(\n",
    "                                lessons_dict[lesson_name].get('n_iteration', 0),\n",
    "                                iteration_number + 1  # Assuming iterations start at 0\n",
    "                            )\n",
    "                        if file_name == 'assessments.json':\n",
    "                            lessons_dict[lesson_name]['assessment_key_path'] = f\"s3://{self.bucket_name}/{key}\"\n",
    "                        elif file_name == 'evaluations.json':\n",
    "                            lessons_dict[lesson_name]['evaluation_key_path'] = f\"s3://{self.bucket_name}/{key}\"\n",
    "\n",
    "            lessons_metadata = {}\n",
    "            for lesson_name, paths in lessons_dict.items():\n",
    "                # Initialize default states\n",
    "                podcast_state = PodcastState.NOT_AVAILABLE\n",
    "                assessment_state = AssessmentState.NOT_AVAILABLE\n",
    "                evaluation_state = EvaluationState.NOT_AVAILABLE\n",
    "                grade = \"Default\"\n",
    "                default_date = datetime(2023, 1, 1)\n",
    "\n",
    "                # Determine states based on presence of keys\n",
    "                if 'podcast_key_path' in paths:\n",
    "                    podcast_state = PodcastState.LISTENED  # Or add logic to verify listening\n",
    "                if 'assessment_key_path' in paths:\n",
    "                    assessment_state = AssessmentState.TAKEN\n",
    "                if 'evaluation_key_path' in paths:\n",
    "                    evaluation_state = EvaluationState.EVALUATED\n",
    "                # Extract metadata from knowledge_graph.json if available\n",
    "                if 'knowledge_graph_key_path' in paths:\n",
    "                    try:\n",
    "                        knowledge_graph = {\"grade\": \"Default\"}\n",
    "                        grade = \"Default\" #knowledge_graph.get('grade')\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error parsing knowledge_graph.json for lesson {lesson_name}: {e}\")\n",
    "\n",
    "                created_at_str = None\n",
    "                last_generated_assessment_str = None\n",
    "                last_generated_assessment = datetime.fromisoformat(last_generated_assessment_str) if last_generated_assessment_str else default_date\n",
    "                created_at = datetime.fromisoformat(created_at_str) if created_at_str else default_date\n",
    "                lesson_metadata = LessonMetadata(\n",
    "                    podcast_state=podcast_state.value,\n",
    "                    assessment_state=assessment_state.value,\n",
    "                    evaluation_state=evaluation_state.value,\n",
    "                    grade=grade,\n",
    "                    created_at=created_at,\n",
    "                    last_generated_assessment=last_generated_assessment,\n",
    "                    n_iteration=paths.get('n_iteration', 0),\n",
    "                    document_key_path=paths.get('document_key_path', \"\"),\n",
    "                    podcast_key_path=paths.get('podcast_key_path', \"\"),\n",
    "                    assessment_key_path=paths.get('assessment_key_path', \"\"),\n",
    "                    evaluation_key_path=paths.get('evaluation_key_path',\"\"),\n",
    "                )\n",
    "                lessons_metadata[lesson_name] = lesson_metadata\n",
    "\n",
    "            return CourseModel(lessons=lessons_metadata).dict()\n",
    "\n",
    "    def push_metadata(self):\n",
    "        metadata = self._parse_metadata()\n",
    "        \n",
    "        self.file_manager.upload_file(obj=metadata, s3_key=self.path + \"/metadata.json\")\n",
    "        print(\"data pushed to s3\", self.path)\n",
    "        return True\n",
    "    \n",
    "    def update_and_push(self):\n",
    "        metadata = self._parse_metadata()\n",
    "\n",
    "        if self.level == 'user':\n",
    "            pass\n",
    "        elif self.level == 'course':\n",
    "            pass\n",
    "\n",
    "\n",
    "        return 0\n",
    "\n",
    "s3_manager = FileManager(aws_access_key=aws_access_key, aws_secret_key = aws_secret_key, region_name=region_name, bucket_name=BUCKET_NAME)\n",
    "#metadata_user_manager = Metadata(s3_manager, f\"qanqa-prod/{username}\", UserLibraryModel)\n",
    "#metadata_course_manager = Metadata(s3_manager, f\"qanqa-prod/{username}\", CourseModel)\n",
    "#metadata_lesson_manager = Metadata()\n",
    "\n",
    "s3_manager.upload_file({}, \"pablo/metadata.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_manager.check_if_file_exists(\"example_user/AINews/News on 2024/knowledge_graph.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'courses': {'AINews': {'description': 'This is a course on AI News',\n",
       "   'state': 'default',\n",
       "   'level': 'default',\n",
       "   'current_grade': 'default',\n",
       "   'goal': 'default',\n",
       "   'progress': 'default',\n",
       "   'required_effort': 'default',\n",
       "   'created_at': datetime.datetime(2025, 1, 5, 17, 49, 36, tzinfo=tzutc())},\n",
       "  'MatteoPasquinelli': {'description': 'This is a course on Matteo Pasquinelli',\n",
       "   'state': 'default',\n",
       "   'level': 'default',\n",
       "   'current_grade': 'default',\n",
       "   'goal': 'default',\n",
       "   'progress': 'default',\n",
       "   'required_effort': 'default',\n",
       "   'created_at': datetime.datetime(2025, 1, 5, 17, 49, 34, tzinfo=tzutc())},\n",
       "  'World History I': {'description': 'default',\n",
       "   'state': 'default',\n",
       "   'level': 'default',\n",
       "   'current_grade': 'default',\n",
       "   'goal': 'default',\n",
       "   'progress': 'default',\n",
       "   'required_effort': 'default',\n",
       "   'created_at': datetime.datetime(2025, 1, 6, 16, 37, 28, tzinfo=tzutc())}}}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = MetadataManager(s3_manager, 'qanqa-prod/example_user', 'user')._parse_metadata()\n",
    "metadata['courses']['AINews']['description'] = 'This is a course on AI News'\n",
    "metadata['courses']['MatteoPasquinelli']['description'] = 'This is a course on Matteo Pasquinelli'\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lessons': {'Coerced and SemiCoerced labor': {'podcast_state': 'Not Available',\n",
       "   'assessment_state': 'Not Available',\n",
       "   'evaluation_state': 'Not Evaluated',\n",
       "   'grade': 'Default',\n",
       "   'created_at': datetime.datetime(2023, 1, 1, 0, 0),\n",
       "   'last_generated_assessment': datetime.datetime(2023, 1, 1, 0, 0),\n",
       "   'n_iteration': 0,\n",
       "   'document_key_path': 's3://qanqa-prod/example_user/World History I/Coerced and SemiCoerced labor/document.txt',\n",
       "   'podcast_key_path': '',\n",
       "   'assessment_key_path': '',\n",
       "   'evaluation_key_path': ''},\n",
       "  'Innovations and Inventions': {'podcast_state': 'Not Available',\n",
       "   'assessment_state': 'Not Available',\n",
       "   'evaluation_state': 'Not Evaluated',\n",
       "   'grade': 'Default',\n",
       "   'created_at': datetime.datetime(2023, 1, 1, 0, 0),\n",
       "   'last_generated_assessment': datetime.datetime(2023, 1, 1, 0, 0),\n",
       "   'n_iteration': 0,\n",
       "   'document_key_path': 's3://qanqa-prod/example_user/World History I/Innovations and Inventions/document.txt',\n",
       "   'podcast_key_path': '',\n",
       "   'assessment_key_path': '',\n",
       "   'evaluation_key_path': ''},\n",
       "  'Life in Industrial City': {'podcast_state': 'Not Available',\n",
       "   'assessment_state': 'Not Available',\n",
       "   'evaluation_state': 'Not Evaluated',\n",
       "   'grade': 'Default',\n",
       "   'created_at': datetime.datetime(2023, 1, 1, 0, 0),\n",
       "   'last_generated_assessment': datetime.datetime(2023, 1, 1, 0, 0),\n",
       "   'n_iteration': 0,\n",
       "   'document_key_path': 's3://qanqa-prod/example_user/World History I/Life in Industrial City/document.txt',\n",
       "   'podcast_key_path': '',\n",
       "   'assessment_key_path': '',\n",
       "   'evaluation_key_path': ''}}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manager = MetadataManager(s3_manager, 'qanqa-prod/example_user/World History I', 'course')\n",
    "metadata = manager._parse_metadata()\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_metadata_manager = MetadataManager(s3_manager, 'qanqa-prod/example_user/AI Engineering', 'course')\n",
    "course_metadata = course_metadata_manager._parse_metadata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserFeedback {'podcast_state': 'Listened', 'assessment_state': 'Not Available', 'evaluation_state': 'Not Evaluated', 'grade': 'Default', 'created_at': datetime.datetime(2023, 1, 1, 0, 0), 'last_generated_assessment': datetime.datetime(2023, 1, 1, 0, 0), 'n_iteration': 0, 'document_key_path': 's3://qanqa-prod/example_user/AI Engineering/UserFeedback/document.txt', 'podcast_key_path': 's3://qanqa-prod/example_user/AI Engineering/UserFeedback/podcast.mp3', 'assessment_key_path': '', 'evaluation_key_path': ''}\n"
     ]
    }
   ],
   "source": [
    "for key, value in course_metadata['lessons'].items():\n",
    "     if value.get('podcast_state','') != 'Not Available':\n",
    "        print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'duration': '3m 40s', 'id': '1', 'filename': 'UserFeedback - Podcast', 'created_at': '2023-01-01'}]\n"
     ]
    }
   ],
   "source": [
    "d = course_metadata['lessons']\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def parse_audio_files(data):\n",
    "    audio_files = []\n",
    "    # Loop over each key-value pair in the provided JSON-like dict\n",
    "    for key, value in data.items():\n",
    "        # Check if there's a non-empty podcast key path indicating an audio file\n",
    "        if value.get('podcast_key_path'):\n",
    "            # Construct audio file information using available data or hard-coded defaults\n",
    "            duration = '3m 40s'  # Hard-coded duration as placeholder\n",
    "            file_id = '1'        # Hard-coded id as placeholder\n",
    "            filename = f\"{key} - Podcast\"  # Create filename using the key\n",
    "            # Format created_at date if available, else use a default date\n",
    "            created_at_obj = value.get('created_at')\n",
    "            if isinstance(created_at_obj, datetime):\n",
    "                created_at = created_at_obj.strftime('%Y-%m-%d')\n",
    "            else:\n",
    "                created_at = '2025-01-01'  # Default date if not provided\n",
    "\n",
    "            # Append constructed audio file dict to the list\n",
    "            audio_files.append({\n",
    "                'duration': duration,\n",
    "                'id': file_id,\n",
    "                'filename': filename,\n",
    "                'created_at': created_at\n",
    "            })\n",
    "            # Only one match needed, so break after finding the first\n",
    "            break\n",
    "\n",
    "    return audio_files\n",
    "\n",
    "audop_files = parse_audio_files(d)\n",
    "\n",
    "print(audop_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lessons': {'Coerced and SemiCoerced labor': {'podcast_state': 'Not Available',\n",
       "   'assessment_state': 'Not Available',\n",
       "   'evaluation_state': 'Not Evaluated',\n",
       "   'grade': 'Default',\n",
       "   'created_at': datetime.datetime(2023, 1, 1, 0, 0),\n",
       "   'last_generated_assessment': datetime.datetime(2023, 1, 1, 0, 0),\n",
       "   'n_iteration': 0,\n",
       "   'document_key_path': 's3://qanqa-prod/example_user/World History I/Coerced and SemiCoerced labor/document.txt',\n",
       "   'podcast_key_path': '',\n",
       "   'assessment_key_path': '',\n",
       "   'evaluation_key_path': ''},\n",
       "  'Innovations and Inventions': {'podcast_state': 'Not Available',\n",
       "   'assessment_state': 'Not Available',\n",
       "   'evaluation_state': 'Not Evaluated',\n",
       "   'grade': 'Default',\n",
       "   'created_at': datetime.datetime(2023, 1, 1, 0, 0),\n",
       "   'last_generated_assessment': datetime.datetime(2023, 1, 1, 0, 0),\n",
       "   'n_iteration': 0,\n",
       "   'document_key_path': 's3://qanqa-prod/example_user/World History I/Innovations and Inventions/document.txt',\n",
       "   'podcast_key_path': '',\n",
       "   'assessment_key_path': '',\n",
       "   'evaluation_key_path': ''},\n",
       "  'Life in Industrial City': {'podcast_state': 'Not Available',\n",
       "   'assessment_state': 'Not Available',\n",
       "   'evaluation_state': 'Not Evaluated',\n",
       "   'grade': 'Default',\n",
       "   'created_at': datetime.datetime(2023, 1, 1, 0, 0),\n",
       "   'last_generated_assessment': datetime.datetime(2023, 1, 1, 0, 0),\n",
       "   'n_iteration': 0,\n",
       "   'document_key_path': 's3://qanqa-prod/example_user/World History I/Life in Industrial City/document.txt',\n",
       "   'podcast_key_path': '',\n",
       "   'assessment_key_path': '',\n",
       "   'evaluation_key_path': ''}}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Coerced and SemiCoerced labor': {'podcast_state': 'Not Available',\n",
       "  'assessment_state': 'Not Available',\n",
       "  'evaluation_state': 'Not Evaluated',\n",
       "  'grade': 'Default',\n",
       "  'created_at': datetime.datetime(2023, 1, 1, 0, 0),\n",
       "  'last_generated_assessment': datetime.datetime(2023, 1, 1, 0, 0),\n",
       "  'n_iteration': 0,\n",
       "  'document_key_path': 's3://qanqa-prod/example_user/World History I/Coerced and SemiCoerced labor/document.txt',\n",
       "  'podcast_key_path': '',\n",
       "  'assessment_key_path': '',\n",
       "  'evaluation_key_path': ''},\n",
       " 'Innovations and Inventions': {'podcast_state': 'Not Available',\n",
       "  'assessment_state': 'Not Available',\n",
       "  'evaluation_state': 'Not Evaluated',\n",
       "  'grade': 'Default',\n",
       "  'created_at': datetime.datetime(2023, 1, 1, 0, 0),\n",
       "  'last_generated_assessment': datetime.datetime(2023, 1, 1, 0, 0),\n",
       "  'n_iteration': 0,\n",
       "  'document_key_path': 's3://qanqa-prod/example_user/World History I/Innovations and Inventions/document.txt',\n",
       "  'podcast_key_path': '',\n",
       "  'assessment_key_path': '',\n",
       "  'evaluation_key_path': ''},\n",
       " 'Life in Industrial City': {'podcast_state': 'Not Available',\n",
       "  'assessment_state': 'Not Available',\n",
       "  'evaluation_state': 'Not Evaluated',\n",
       "  'grade': 'Default',\n",
       "  'created_at': datetime.datetime(2023, 1, 1, 0, 0),\n",
       "  'last_generated_assessment': datetime.datetime(2023, 1, 1, 0, 0),\n",
       "  'n_iteration': 0,\n",
       "  'document_key_path': 's3://qanqa-prod/example_user/World History I/Life in Industrial City/document.txt',\n",
       "  'podcast_key_path': '',\n",
       "  'assessment_key_path': '',\n",
       "  'evaluation_key_path': ''}}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "course_metadata_manager = MetadataManager(s3_manager, 'qanqa-prod/example_user/World History I', 'course')._parse_metadata()\n",
    "course_metadata_manager['lessons']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "assessment = s3_manager.read_json(s3_key=f\"example_user/AINews/News on 2024/v0/assessments.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AINews {'state': 'default', 'level': 'default', 'current_grade': 'default', 'goal': 'default', 'progress': 'default', 'required_effort': 'default', 'created_at': '2025-01-05 17:49:36+00:00'}\n",
      "MatteoPasquinelli {'state': 'default', 'level': 'default', 'current_grade': 'default', 'goal': 'default', 'progress': 'default', 'required_effort': 'default', 'created_at': '2025-01-05 17:49:34+00:00'}\n"
     ]
    }
   ],
   "source": [
    "docs_metadata = s3_manager.read_json(s3_key=f\"example_user/metadata.json\")['courses']\n",
    "\n",
    "for id, docs in docs_metadata.items():\n",
    "    print(id, docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AINews': {'state': 'default',\n",
       "  'level': 'default',\n",
       "  'current_grade': 'default',\n",
       "  'goal': 'default',\n",
       "  'progress': 'default',\n",
       "  'required_effort': 'default',\n",
       "  'created_at': '2025-01-05 17:49:36+00:00'},\n",
       " 'MatteoPasquinelli': {'state': 'default',\n",
       "  'level': 'default',\n",
       "  'current_grade': 'default',\n",
       "  'goal': 'default',\n",
       "  'progress': 'default',\n",
       "  'required_effort': 'default',\n",
       "  'created_at': '2025-01-05 17:49:34+00:00'}}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_manager.upload_file({}, \"example_user/metadata.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "username = 'pablo'\n",
    "docs_metadata = s3_manager.read_json(s3_key=f\"{username}/metadata.json\")\n",
    "docs_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File uploaded to s3://qanqa-prod/pablo-test/metadata.json\n",
      "File uploaded to s3://qanqa-prod/pablo-test/Course Test name/metadata.json\n"
     ]
    }
   ],
   "source": [
    "#Create Course (Add a Folder and create first metadata.json)\n",
    "from datetime import datetime\n",
    "username = 'pablo-test'\n",
    "\n",
    "course_form = {\n",
    "    \"course_name\": \"Course Test name\",\n",
    "    \"course_goal\": \"Course Test Goal\",\n",
    "    \"required_effort\": \"easy\",\n",
    "    \"created_at\" : datetime.now().strftime(format=\"%Y-%m-%d-%H:%M\")\n",
    "}\n",
    "\n",
    "s3_manager.upload_file({}, f\"{username}/metadata.json\")\n",
    "s3_manager.upload_file({}, f\"{username}/{course_form[\"course_name\"]}/metadata.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File uploaded to s3://qanqa-prod/example_user/metadata.json\n",
      "data pushed to s3 example_user\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_metadata_manager = MetadataManager(s3_manager, 'qanqa-prod/example_user/', level= 'user')\n",
    "_ = user_metadata_manager.push_metadata()\n",
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'courses': {'AINews': {'state': 'default',\n",
       "   'level': 'default',\n",
       "   'current_grade': 'default',\n",
       "   'goal': 'default',\n",
       "   'progress': 'default',\n",
       "   'required_effort': 'default',\n",
       "   'created_at': '2025-01-05 17:49:36+00:00'},\n",
       "  'MatteoPasquinelli': {'state': 'default',\n",
       "   'level': 'default',\n",
       "   'current_grade': 'default',\n",
       "   'goal': 'default',\n",
       "   'progress': 'default',\n",
       "   'required_effort': 'default',\n",
       "   'created_at': '2025-01-05 17:49:34+00:00'}}}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_metadata = s3_manager.read_json(s3_key=\"example_user/metadata.json\")\n",
    "docs_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Domain Classes (Library, Course, Lesson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class PodcastState(Enum):\n",
    "    NOT_AVAILABLE = \"Not Available\"\n",
    "    AVAILABLE = \"Available\"\n",
    "    LISTENED = \"Listened\"\n",
    "\n",
    "class AssessmentState(Enum):\n",
    "    NOT_AVAILABLE = \"Not Available\"\n",
    "    AVAILABLE = \"Available\"\n",
    "    TAKED = \"Taked\"\n",
    "\n",
    "class GradeState(Enum):\n",
    "    EVALUATED = \"Evaluated\"\n",
    "    NOT_EVALUATED = \"Not Evaluated\"\n",
    "\n",
    "    APPROVED = \"Approved\"\n",
    "    NOT_APPROVED = \"Not Approved\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from datetime import datetime\n",
    "\n",
    "class Lesson:\n",
    "    def __init__(self, title, document_url, lesson_id=None):\n",
    "        self.lesson_id = lesson_id or str(uuid.uuid4())\n",
    "        self.title = title\n",
    "        self.document_url = document_url\n",
    "        self.podcast_state = PodcastState.NOT_AVAILABLE\n",
    "        self.assessment_state = AssessmentState.NOT_AVAILABLE\n",
    "        self.last_edited_time = datetime.now()\n",
    "\n",
    "    def to_dict(self):\n",
    "        \"\"\"\n",
    "        Convert the Lesson to a dictionary for JSON serialization\n",
    "        (which will be stored in metadata.json).\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"lesson_id\": self.lesson_id,\n",
    "            \"title\": self.title,\n",
    "            \"document_url\": self.document_url,\n",
    "            \"podcast_state\": self.podcast_state.value,\n",
    "            \"assessment_state\": self.assessment_state.value,\n",
    "            \"last_edited_time\": str(self.last_edited_time)\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, data_dict):\n",
    "        \"\"\"\n",
    "        Create a Lesson instance from a dictionary loaded from S3.\n",
    "        \"\"\"\n",
    "        lesson = cls(\n",
    "            title=data_dict[\"title\"],\n",
    "            document_url=data_dict[\"document_url\"],\n",
    "            lesson_id=data_dict[\"lesson_id\"]\n",
    "        )\n",
    "        # Restore states\n",
    "        lesson.podcast_state = PodcastState(data_dict[\"podcast_state\"])\n",
    "        lesson.assessment_state = AssessmentState(data_dict[\"assessment_state\"])\n",
    "        lesson.last_edited_time = datetime.fromisoformat(data_dict[\"last_edited_time\"])\n",
    "        return lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Course:\n",
    "    def __init__(self, name, description, course_id=None):\n",
    "        self.course_id = course_id or str(uuid.uuid4())\n",
    "        self.name = name\n",
    "        self.description = description\n",
    "        self.lessons = {}\n",
    "        self.last_edited_time = datetime.now()\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"course_id\": self.course_id,\n",
    "            \"name\": self.name,\n",
    "            \"description\": self.description,\n",
    "            \"last_edited_time\": str(self.last_edited_time),\n",
    "            \"lessons\": {\n",
    "                lesson_id: lesson.to_dict() \n",
    "                for lesson_id, lesson in self.lessons.items()\n",
    "            }\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, data_dict):\n",
    "        course = cls(\n",
    "            name=data_dict[\"name\"],\n",
    "            description=data_dict[\"description\"],\n",
    "            course_id=data_dict[\"course_id\"]\n",
    "        )\n",
    "        course.last_edited_time = datetime.fromisoformat(data_dict[\"last_edited_time\"])\n",
    "        for lesson_id, lesson_data in data_dict[\"lessons\"].items():\n",
    "            lesson = Lesson.from_dict(lesson_data)\n",
    "            course.lessons[lesson_id] = lesson\n",
    "        return course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Library:\n",
    "    def __init__(self, user_id):\n",
    "        self.user_id = user_id\n",
    "        self.courses = {}\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"user_id\": self.user_id,\n",
    "            \"courses\": {\n",
    "                course_id: course.to_dict()\n",
    "                for course_id, course in self.courses.items()\n",
    "            }\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, data_dict):\n",
    "        library = cls(user_id=data_dict[\"user_id\"])\n",
    "        for course_id, course_data in data_dict[\"courses\"].items():\n",
    "            course_obj = Course.from_dict(course_data)\n",
    "            library.courses[course_id] = course_obj\n",
    "        return library"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
